#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Identify Idle Load Balancers (ALB/NLB/Classic), with three modes:
- Offline fixtures (for local tests)
- Hybrid: costs from local CUR fixture, live AWS for inventory+metrics (read-only)
- Online: Athena CUR + live AWS

Idle definition over lookback window:
  * ALB: RequestCount Sum <= 1
  * NLB: ProcessedBytes Sum <= 1024 AND ActiveFlowCount Avg <= 0.01
  * GatewayLB: ActiveFlowCount Avg <= 0.01
  * Classic: RequestCount Sum <= 1

Costs:
- default (online): Athena query over last full calendar month (unblended)
- offline: fixtures/athena_cost.csv via athena_query(..., offline=True)
- hybrid: --cost-from-fixture <path> to a CSV (e.g., generated by cur_to_fixture.py)
"""
import argparse
import csv
import datetime
import itertools
import os
import sys
import time
import json

import boto3
from botocore.config import Config

# ---------- Global client config ----------
CFG = Config(retries={'max_attempts': 10, 'mode': 'standard'})

# ---------- Utility helpers ----------

def load_account_map(path):
    m = {}
    if not path or not os.path.exists(path):
        return m
    with open(path, newline='') as f:
        for r in csv.DictReader(f):
            aid = r.get('Account Id') or r.get('AccountId') or r.get('Id')
            if not aid:
                continue
            m[str(aid)] = r.get('Account Name', '') or r.get('Name', '')
    return m

def load_cost_fixture(path):
    rows = []
    if not path:
        return rows
    with open(path, newline='') as f:
        for r in csv.DictReader(f):
            rows.append(r)
    return rows

def all_regions(session, offline=False, fixtures_dir='fixtures'):
    if offline:
        # infer regions from local describe fixtures
        f1 = os.path.join(fixtures_dir, 'elbv2_describe.json')
        f2 = os.path.join(fixtures_dir, 'elb_describe.json')
        regs = set()
        if os.path.exists(f1):
            try:
                data = json.load(open(f1))
                for item in data.get('Regions', []):
                    regs.add(item['Region'])
            except Exception:
                pass
        if os.path.exists(f2):
            try:
                data = json.load(open(f2))
                for item in data.get('Regions', []):
                    regs.add(item['Region'])
            except Exception:
                pass
        return sorted(regs or ['us-east-1'])
    ec2 = session.client('ec2', config=CFG)
    return [r['RegionName'] for r in ec2.describe_regions(AllRegions=True)['Regions']
            if r.get('OptInStatus') in (None, 'opt-in-not-required', 'opted-in')]

def athena_query(session, q, db, workgroup, offline=False, fixtures_dir='fixtures'):
    if offline:
        # read local CSV fixture produced by cur_to_fixture.py
        path = os.path.join(fixtures_dir, 'athena_cost.csv')
        rows = []
        with open(path, newline='') as f:
            for r in csv.DictReader(f):
                rows.append(r)
        return rows
    # online Athena
    athena = session.client('athena', config=CFG)
    qid = athena.start_query_execution(
        QueryString=q,
        QueryExecutionContext={'Database': db},
        WorkGroup=workgroup
    )['QueryExecutionId']
    while True:
        s = athena.get_query_execution(QueryExecutionId=qid)['QueryExecution']['Status']['State']
        if s in ('SUCCEEDED', 'FAILED', 'CANCELLED'):
            break
        time.sleep(1.5)
    if s != 'SUCCEEDED':
        raise RuntimeError(f"Athena query failed: {s}")
    res = athena.get_query_results(QueryExecutionId=qid)
    headers = [c['VarCharValue'] for c in res['ResultSet']['Rows'][0]['Data']]
    out_rows = []
    for r in res['ResultSet']['Rows'][1:]:
        row = {}
        for h, d in itertools.zip_longest(headers, r['Data']):
            row[h] = d.get('VarCharValue') if d else None
        out_rows.append(row)
    return out_rows

def list_lbs(session, region, offline=False, fixtures_dir='fixtures'):
    if offline:
        v2, classic = [], []
        dv2_path = os.path.join(fixtures_dir, 'elbv2_describe.json')
        dcl_path = os.path.join(fixtures_dir, 'elb_describe.json')
        if os.path.exists(dv2_path):
            data_v2 = json.load(open(dv2_path))
            for reg in data_v2.get('Regions', []):
                if reg['Region'] != region:
                    continue
                v2.extend(reg.get('LoadBalancers', []))
        if os.path.exists(dcl_path):
            data_cl = json.load(open(dcl_path))
            for reg in data_cl.get('Regions', []):
                if reg['Region'] != region:
                    continue
                classic.extend(reg.get('LoadBalancerDescriptions', []))
        return v2, classic
    elbv2 = session.client('elbv2', region_name=region, config=CFG)
    elb = session.client('elb', region_name=region, config=CFG)
    v2 = []
    paginator = elbv2.get_paginator('describe_load_balancers')
    for page in paginator.paginate():
        v2.extend(page.get('LoadBalancers', []))
    classic = []
    paginator = elb.get_paginator('describe_load_balancers')
    for page in paginator.paginate():
        classic.extend(page.get('LoadBalancerDescriptions', []))
    return v2, classic

def metrics_fixture_lookup(fixtures_dir):
    path = os.path.join(fixtures_dir, 'metrics.json')
    return json.load(open(path)) if os.path.exists(path) else {}

def cw_sum(session, region, ns, metric, dims, start, end, stat='Sum',
           offline=False, fixtures=None):
    if offline:
        key = dims[0]['Value']
        return float((fixtures or {}).get(key, {}).get(metric + stat, 0.0))
    cw = session.client('cloudwatch', region_name=region, config=CFG)
    r = cw.get_metric_statistics(
        Namespace=ns, MetricName=metric, Dimensions=dims,
        StartTime=start, EndTime=end,
        Period=max(300, int((end - start).total_seconds() / 144)),
        Statistics=[stat]
    )
    pts = r.get('Datapoints', [])
    if not pts:
        return 0.0
    return sum(p[stat] for p in pts)

def cw_avg(session, region, ns, metric, dims, start, end,
           offline=False, fixtures=None):
    if offline:
        key = dims[0]['Value']
        return float((fixtures or {}).get(key, {}).get(metric + 'Average', 0.0))
    cw = session.client('cloudwatch', region_name=region, config=CFG)
    r = cw.get_metric_statistics(
        Namespace=ns, MetricName=metric, Dimensions=dims,
        StartTime=start, EndTime=end,
        Period=max(300, int((end - start).total_seconds() / 144)),
        Statistics=['Average']
    )
    pts = r.get('Datapoints', [])
    if not pts:
        return 0.0
    return sum(p['Average'] for p in pts) / len(pts)

def arn_for_classic(lb_name, region, account_id):
    return f"arn:aws:elasticloadbalancing:{region}:{account_id}:loadbalancer/{lb_name}"

def short_lb_id_from_arn(arn):
    # arn:...:loadbalancer/<short>
    if ':loadbalancer/' in arn:
        return arn.split(':loadbalancer/')[1]
    return arn

def to_iso(val):
    if not val:
        return ''
    if isinstance(val, str):
        return val
    try:
        return val.isoformat()
    except Exception:
        return str(val)

def azs_to_str(v2_az_list):
    if not v2_az_list:
        return ''
    parts = []
    for az in v2_az_list:
        if isinstance(az, dict):
            parts.append(az.get('SubnetId') or az.get('ZoneName') or az.get('ZoneId') or '')
        else:
            parts.append(str(az))
    return ','.join([p for p in parts if p])

# ---------- Main ----------

def main():
    ap = argparse.ArgumentParser(description="Identify idle ELBs (ALB/NLB/Classic)")
    ap.add_argument('--lookback-hours', type=int, default=336, help='Hours to analyze for zero traffic')
    ap.add_argument('--cost-threshold', type=float, default=0.0, help='Min annual saving ($) to include')
    ap.add_argument('--athena-db', default='wivdb')
    ap.add_argument('--athena-table', default='wiv_cur')
    ap.add_argument('--workgroup', default='primary')
    ap.add_argument('--regions', nargs='*', help='Subset of regions (default: discover all)')
    ap.add_argument('--account-id', default=None, help='Override for classic ARN construction')
    ap.add_argument('--output', default='out/idle_elb.csv')
    ap.add_argument('--offline', action='store_true', help='Use local fixtures for everything')
    ap.add_argument('--fixtures-dir', default='fixtures', help='Fixtures dir for offline mode')
    ap.add_argument('--account-map', default='fixtures/accounts.csv', help='CSV with Account Id,Account Name')
    # HYBRID: local-costs switch
    ap.add_argument('--cost-from-fixture', default=None,
                    help='Path to local CSV with costs (athena_cost.csv). If set, do NOT query Athena; still call AWS for inventory & metrics.')
    args = ap.parse_args()

    session = boto3.Session()
    regions = args.regions or all_regions(session, offline=args.offline, fixtures_dir=args.fixtures_dir)

    look_end = datetime.datetime.utcnow()
    look_start = look_end - datetime.timedelta(hours=args.lookback_hours)

    # ---- Load costs (Athena OR local fixture OR offline fixture) ----
    if args.cost_from_fixture:
        # HYBRID: take costs from local CSV, join to live AWS inventory/metrics
        cost_rows = load_cost_fixture(args.cost_from_fixture)
    else:
        # OFFLINE uses athena_query(..., offline=True) which reads fixtures/athena_cost.csv
        sql_path = os.path.join('sql', 'elb_cost_last_month.sql')
        if not args.offline:
            if not os.path.exists(sql_path):
                sys.exit(f"Missing SQL file: {sql_path}")
            sql = open(sql_path, 'r').read() \
                .replace('${athena_db}', args.athena_db) \
                .replace('${athena_table}', args.athena_table)
            cost_rows = athena_query(session, sql, args.athena_db, args.workgroup,
                                     offline=False, fixtures_dir=args.fixtures_dir)
        else:
            cost_rows = athena_query(session, None, None, None,
                                     offline=True, fixtures_dir=args.fixtures_dir)

    cost_by_arn = {r['Resource Id']: r for r in cost_rows}

    # Account names (optional)
    acct_names = load_account_map(args.account_map)

    fixtures = metrics_fixture_lookup(args.fixtures_dir) if args.offline else None
    out_rows = []
    # STS account (for classic ARN construction when cost row missing)
    account_id = args.account_id
    if not account_id:
        try:
            account_id = boto3.client('sts').get_caller_identity()['Account']
        except Exception:
            account_id = '000000000000'

    # de-dup key across regions
    seen = set()  # (region, arn)

    for region in regions:
        v2_list, classic_list = list_lbs(session, region, offline=args.offline, fixtures_dir=args.fixtures_dir)

        # ----- ELBv2 (ALB/NLB/Gateway) -----
        for lb in v2_list:
            arn = lb.get('LoadBalancerArn')
            if not arn:
                continue
            key = (region, arn)
            if key in seen:
                continue
            seen.add(key)

            # Only consider CURRENTLY ONLINE LBs
            state_code = (lb.get('State') or {}).get('Code')
            if state_code and state_code != 'active':
                continue

            lb_type = lb.get('Type')
            name = lb.get('LoadBalancerName', '')
            short_id = short_lb_id_from_arn(arn)

            # Metrics-based idle detection
            idle = False
            if lb_type == 'application':
                req = cw_sum(session, region, 'AWS/ApplicationELB', 'RequestCount',
                             [{'Name': 'LoadBalancer', 'Value': short_id}],
                             look_start, look_end, 'Sum', offline=args.offline, fixtures=fixtures)
                idle = (req <= 1)
            elif lb_type == 'network':
                bytes_sum = cw_sum(session, region, 'AWS/NetworkELB', 'ProcessedBytes',
                                   [{'Name': 'LoadBalancer', 'Value': short_id}],
                                   look_start, look_end, 'Sum', offline=args.offline, fixtures=fixtures)
                flows_avg = cw_avg(session, region, 'AWS/NetworkELB', 'ActiveFlowCount',
                                   [{'Name': 'LoadBalancer', 'Value': short_id}],
                                   look_start, look_end, offline=args.offline, fixtures=fixtures)
                idle = (bytes_sum <= 1024) and (flows_avg <= 0.01)
            elif lb_type == 'gateway':
                flows_avg = cw_avg(session, region, 'AWS/GatewayELB', 'ActiveFlowCount',
                                   [{'Name': 'LoadBalancer', 'Value': short_id}],
                                   look_start, look_end, offline=args.offline, fixtures=fixtures)
                idle = (flows_avg <= 0.01)
            else:
                continue

            if not idle:
                continue

            cost = cost_by_arn.get(arn)
            monthly_cost = float(cost['Monthly Cost']) if cost and cost.get('Monthly Cost') else 0.0
            annual_saving = int(round(monthly_cost * 12))
            if annual_saving < args.cost_threshold:
                continue

            acc_id = str(cost['Account Id']) if cost and cost.get('Account Id') else account_id
            out_rows.append({
                'Account Id': acc_id,
                'Account Name': acct_names.get(acc_id, ''),
                'Region': region,
                'Resource Id': arn,
                'Resource Name': name,
                'Scheme': lb.get('Scheme', ''),
                'Type': lb_type,
                'VPC Id': lb.get('VpcId', ''),
                'Availability Zones': azs_to_str(lb.get('AvailabilityZones', [])),
                'Created Time': to_iso(lb.get('CreatedTime')),
                'Security Groups': ','.join(lb.get('SecurityGroups', [])) if lb.get('SecurityGroups') else '',
                'Monthly Usage Hours': cost.get('Monthly Usage Hours', '') if cost else '',
                'Monthly Cost': monthly_cost,
                'Annual Saving': annual_saving
            })

        # ----- Classic ELB -----
        for lb in classic_list:
            name = lb.get('LoadBalancerName', '')
            if not name:
                continue
            arn = arn_for_classic(name, region, account_id)
            key = (region, arn)
            if key in seen:
                continue
            seen.add(key)

            req = cw_sum(session, region, 'AWS/ELB', 'RequestCount',
                         [{'Name': 'LoadBalancerName', 'Value': name}],
                         look_start, look_end, 'Sum', offline=args.offline, fixtures=fixtures)
            if req > 1:
                continue

            cost = cost_by_arn.get(arn)
            monthly_cost = float(cost['Monthly Cost']) if cost and cost.get('Monthly Cost') else 0.0
            annual_saving = int(round(monthly_cost * 12))
            if annual_saving < args.cost_threshold:
                continue

            acc_id = str(cost['Account Id']) if cost and cost.get('Account Id') else account_id
            # Heuristic for scheme on classic
            scheme = 'internal' if lb.get('SecurityGroups') else 'internet-facing'

            out_rows.append({
                'Account Id': acc_id,
                'Account Name': acct_names.get(acc_id, ''),
                'Region': region,
                'Resource Id': arn,
                'Resource Name': name,
                'Scheme': scheme,
                'Type': 'classic',
                'VPC Id': lb.get('VPCId', ''),
                'Availability Zones': ','.join(lb.get('AvailabilityZones', [])) if lb.get('AvailabilityZones') else '',
                'Created Time': to_iso(lb.get('CreatedTime')),
                'Security Groups': ','.join(lb.get('SecurityGroups', [])) if lb.get('SecurityGroups') else '',
                'Monthly Usage Hours': cost.get('Monthly Usage Hours', '') if cost else '',
                'Monthly Cost': monthly_cost,
                'Annual Saving': annual_saving
            })

    os.makedirs(os.path.dirname(args.output), exist_ok=True)
    fields = [
        'Account Id','Account Name','Region','Resource Id','Resource Name','Scheme','Type','VPC Id',
        'Availability Zones','Created Time','Security Groups',
        'Monthly Usage Hours','Monthly Cost','Annual Saving'
    ]
    with open(args.output, 'w', newline='') as f:
        w = csv.DictWriter(f, fieldnames=fields)
        w.writeheader()
        for r in out_rows:
            w.writerow(r)

    print(f"Wrote {len(out_rows)} idle LBs → {args.output}")

if __name__ == '__main__':
    main()
